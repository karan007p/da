Q2).Consideranytextparagraph.Preprocessthetexttoremoveanyspeci
 digits.
 Generatethesummaryusingextracti
 vesummarizationpprocess.
 Ans:
 Importre
 Importnltk
 Fromnltk.corpusi
 Fromnltk.tokeni
 mportstopwords
 zeimportsent_tokeni
 ze,word_tokeni
 Fromheapqimportnlargest
 #Sampletextparagraphyoucanwriteanytext
 Text=“Naturallanguageprocessi
 ze
 ng(NLP)isasubfieldoflingui
 informati
 onengineering,andarti
 fici
 alintel
 ligenceconcernedwiththei
 computersandhumanlanguages,inparticul
 alcharactersand
 stics,computersci
 ence,
 nteracti
 onsbetween
 arhowtoprogramcomputerstoprocessand
 analyzelargeamountsofnaturall
 anguagedata.Challengesinnaturall
 anguageprocessing
 frequentl
 yinvolvespeechrecogni
 tion,naturall
 generati
 on.Thehistoryofnaturall
 anguageunderstanding,andnaturall
 anguageprocessinggenerall
 anguage
 ystartedinthe1950s,al
 though
 workcanbefoundfromearlierperiods.”
#Removespecialcharactersanddigits
 Text=re.sub(‘
 [^a-zA-Z]
 ’,‘‘
 ,text)
 #Tokenizethetextintosentences
 Sentences=sent_tokeni
 ze(text)
 #Tokenizeeachsentenceintowordsandremovestopwords
 Stop_words=set(stopwords.words(‘
 english’
 Words=[]
 Forsentenceinsentences:
 Words.extend(word_tokeni
 ze(sentence))
 ))
 Words=[word.lower()forwordinwordsifword.l
 ower()notinstop_words]
 #Calculatewordfrequency
 Word_freq=nltk.FreqDi
 st(words)
 #Calculatesentencescoresbasedonwordfrequency
 Sentence_scores={}
 Forsentenceinsentences:
 Forwordinword_tokenize(sentence.
 Ifwordinword_freq:
 Iflen(sentence.
 split(‘‘
 ))<30:
 lower()):
 Ifsentencenotinsentence_scores:
 Sentence_scores[sentence]=word_freq[
 Else:
 word]
 Sentence_scores[sentence]+=word_freq[
 word]
 #Generatesummarybyselectingtop3sentenceswithhighestscores
Summary_sentences=nlargest(3,sentence_scores,key=sentence_scores.
 get)
 Summary=‘‘.join(summary_sentences)
 Print(summary)
